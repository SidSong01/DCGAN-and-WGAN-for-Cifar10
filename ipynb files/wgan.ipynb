{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "from dataSet import ReadFromTFRecord, DataBatch, ImgShow\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy\n",
    "from numpy import cov\n",
    "from numpy import trace\n",
    "from numpy import iscomplexobj\n",
    "from numpy import asarray\n",
    "from numpy.random import shuffle\n",
    "from scipy.linalg import sqrtm\n",
    "from skimage.transform import resize\n",
    "from numpy import asarray\n",
    "from numpy import expand_dims\n",
    "from numpy import log\n",
    "from numpy import mean\n",
    "from numpy import exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_inception_score(p_yx, eps=1E-16):\n",
    "    # calculate p(y)\n",
    "    p_y = expand_dims(p_yx.mean(axis=0), 0)\n",
    "    # kl divergence for each image\n",
    "    kl_d = p_yx * (log(p_yx + eps) - log(p_y + eps))\n",
    "    # sum over classes\n",
    "    sum_kl_d = kl_d.sum(axis=1)\n",
    "    # average over images\n",
    "    avg_kl_d = mean(sum_kl_d)\n",
    "    # undo the logs\n",
    "    is_score = exp(avg_kl_d)\n",
    "    return is_score\n",
    "\n",
    " \n",
    "def scale_images(images, new_shape):\n",
    "    images_list = list()\n",
    "    for image in images:\n",
    "        # resize with nearest neighbor interpolation\n",
    "        new_image = resize(image, new_shape, 0)\n",
    "        # store\n",
    "        images_list.append(new_image)\n",
    "    return asarray(images_list)\n",
    " \n",
    "def batch_preprocess(data_batch):\n",
    "\n",
    "    batch = sess.run(data_batch)\n",
    "    \n",
    "    batch_images = np.reshape(batch, [-1, 3, 32, 32]).transpose((0, 2, 3, 1))\n",
    "    batch_images = batch_images * 2 - 1\n",
    "    return  batch_images\n",
    "\n",
    "\n",
    "def Dir():\n",
    "    import os\n",
    "    if not os.path.isdir('Wgan_ckpt'):\n",
    "        os.mkdir('Wgan_ckpt')\n",
    "    if not os.path.isdir('Wgan_trainLog'):\n",
    "        os.mkdir('Wgan_trainLog')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_shape = [-1,32,32,3]\n",
    "data_total = 5000 \n",
    "batch_size = 64 \n",
    "noise_size = 128 \n",
    "max_iters = 35000\n",
    "learning_rate = 5e-5\n",
    "CRITIC_NUM = 5\n",
    "CLIP = [-0.1,0.1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-4-3551adf8cdd3>:5: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.Dense instead.\n",
      "WARNING:tensorflow:From /home/lingyis/.conda/envs/8810/lib/python3.6/site-packages/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "WARNING:tensorflow:From <ipython-input-4-3551adf8cdd3>:7: batch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.BatchNormalization instead.  In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.batch_normalization` documentation).\n",
      "WARNING:tensorflow:From <ipython-input-4-3551adf8cdd3>:12: conv2d_transpose (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.keras.layers.Conv2DTranspose` instead.\n",
      "WARNING:tensorflow:From <ipython-input-4-3551adf8cdd3>:41: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.keras.layers.Conv2D` instead.\n",
      "WARNING:tensorflow:From /home/lingyis/.conda/envs/8810/lib/python3.6/site-packages/tensorflow_core/python/training/rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/lingyis/gan/dataSet.py:59: The name tf.train.match_filenames_once is deprecated. Please use tf.io.match_filenames_once instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/lingyis/gan/dataSet.py:60: string_input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(string_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n",
      "WARNING:tensorflow:From /home/lingyis/.conda/envs/8810/lib/python3.6/site-packages/tensorflow_core/python/training/input.py:277: input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(input_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n",
      "WARNING:tensorflow:From /home/lingyis/.conda/envs/8810/lib/python3.6/site-packages/tensorflow_core/python/training/input.py:189: limit_epochs (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensors(tensor).repeat(num_epochs)`.\n",
      "WARNING:tensorflow:From /home/lingyis/.conda/envs/8810/lib/python3.6/site-packages/tensorflow_core/python/training/input.py:198: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From /home/lingyis/.conda/envs/8810/lib/python3.6/site-packages/tensorflow_core/python/training/input.py:198: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From /home/lingyis/gan/dataSet.py:61: TFRecordReader.__init__ (from tensorflow.python.ops.io_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.TFRecordDataset`.\n",
      "WARNING:tensorflow:From /home/lingyis/gan/dataSet.py:66: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/lingyis/gan/dataSet.py:69: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/lingyis/gan/dataSet.py:51: shuffle_batch (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.shuffle(min_after_dequeue).batch(batch_size)`.\n"
     ]
    }
   ],
   "source": [
    "def GeNet(z, channel, is_train=True):\n",
    "\n",
    "    with tf.variable_scope(\"generator\", reuse=(not is_train)):\n",
    "\n",
    "        layer1 = tf.layers.dense(z, 4 * 4 * 512)\n",
    "        layer1 = tf.reshape(layer1, [-1, 4, 4, 512])\n",
    "        layer1 = tf.layers.batch_normalization(layer1, training=is_train,)\n",
    "        layer1 = tf.nn.relu(layer1)\n",
    "\n",
    "        layer2 = tf.layers.conv2d_transpose(layer1, 256, 3, strides=2, padding='same',\n",
    "                                            kernel_initializer=tf.random_normal_initializer(0, 0.02),\n",
    "                                            bias_initializer=tf.random_normal_initializer(0, 0.02))\n",
    "        layer2 = tf.layers.batch_normalization(layer2, training=is_train)\n",
    "        layer2 = tf.nn.relu(layer2)\n",
    "\n",
    "        layer3 = tf.layers.conv2d_transpose(layer2, 128, 3, strides=2, padding='same',\n",
    "                                            kernel_initializer=tf.random_normal_initializer(0, 0.02),\n",
    "                                            bias_initializer=tf.random_normal_initializer(0, 0.02))\n",
    "        layer3 = tf.layers.batch_normalization(layer3, training=is_train)\n",
    "        layer3 = tf.nn.relu(layer3)\n",
    "\n",
    "        layer4 = tf.layers.conv2d_transpose(layer3, 64, 3, strides=2, padding='same',\n",
    "                                            kernel_initializer=tf.random_normal_initializer(0, 0.02),\n",
    "                                            bias_initializer=tf.random_normal_initializer(0, 0.02))\n",
    "        layer4 = tf.layers.batch_normalization(layer4, training=is_train)\n",
    "        layer4 = tf.nn.relu(layer4)\n",
    "\n",
    "        logits = tf.layers.conv2d_transpose(layer4, channel, 3, strides=1, padding='same',\n",
    "                                            kernel_initializer=tf.random_normal_initializer(0, 0.02),\n",
    "                                            bias_initializer=tf.random_normal_initializer(0, 0.02))\n",
    "        # outputs\n",
    "        outputs = tf.tanh(logits)\n",
    "\n",
    "        return logits,outputs\n",
    "\n",
    "\n",
    "def DiNet(inputs_img, reuse=False, GAN = False,GP= False,alpha=0.2):\n",
    "\n",
    "    with tf.variable_scope(\"discriminator\", reuse=reuse):\n",
    "\n",
    "        layer1 = tf.layers.conv2d(inputs_img, 128, 3, strides=2, padding='same')\n",
    "        if GP is False:\n",
    "            layer1 = tf.layers.batch_normalization(layer1, training=True)\n",
    "        layer1 = tf.nn.leaky_relu(layer1,alpha=alpha)\n",
    "\n",
    "        layer2 = tf.layers.conv2d(layer1, 256, 3, strides=2, padding='same')\n",
    "        if GP is False:\n",
    "            layer2 = tf.layers.batch_normalization(layer2, training=True)\n",
    "        layer2 = tf.nn.leaky_relu(layer2, alpha=alpha)\n",
    "\n",
    "        layer3 = tf.layers.conv2d(layer2, 512, 3, strides=2, padding='same')\n",
    "        if GP is False:\n",
    "            layer3 = tf.layers.batch_normalization(layer3, training=True)\n",
    "        layer3 = tf.nn.leaky_relu(layer3, alpha=alpha)\n",
    "        layer3 = tf.reshape(layer3, [-1, 4*4* 512])\n",
    "\n",
    "        logits = tf.layers.dense(layer3, 1)\n",
    "\n",
    "        if GAN:\n",
    "            outputs = None\n",
    "        else:\n",
    "            outputs = tf.sigmoid(logits)\n",
    "\n",
    "        return logits, outputs\n",
    "\n",
    "#inputs\n",
    "inputs_real = tf.placeholder(tf.float32, [None, real_shape[1], real_shape[2], real_shape[3]], name='inputs_real')\n",
    "inputs_noise = tf.placeholder(tf.float32, [None, noise_size], name='inputs_noise')\n",
    "_,g_outputs = GeNet(inputs_noise, real_shape[3], is_train=True)\n",
    "_,g_test = GeNet(inputs_noise, real_shape[3], is_train=False)\n",
    "\n",
    "d_logits_real, _ = DiNet(inputs_real,GAN=True)\n",
    "d_logits_fake, _ = DiNet(g_outputs,GAN=True,reuse=True)\n",
    "\n",
    "#-original loss function\n",
    "g_loss = tf.reduce_mean(-d_logits_fake)\n",
    "\n",
    "d_loss = tf.reduce_mean(d_logits_fake - d_logits_real)\n",
    "\n",
    "\n",
    "train_vars = tf.trainable_variables()\n",
    "g_vars = [var for var in train_vars if var.name.startswith(\"generator\")]\n",
    "d_vars = [var for var in train_vars if var.name.startswith(\"discriminator\")]\n",
    "\n",
    "# Optimizer\n",
    "with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)):\n",
    "    g_train_opt = tf.train.RMSPropOptimizer(learning_rate).minimize(g_loss, var_list=g_vars)\n",
    "    d_train_opt = tf.train.RMSPropOptimizer(learning_rate).minimize(d_loss, var_list=d_vars)\n",
    "\n",
    "# clip\n",
    "d_clip_opt = [tf.assign(var, tf.clip_by_value(var, CLIP[0], CLIP[1])) for var in d_vars]\n",
    "\n",
    "# read TFR\n",
    "[data,label] = ReadFromTFRecord(sameName= r'./TFR/class1-*',isShuffle= False,datatype= tf.float64,\n",
    "                                labeltype= tf.int64,isMultithreading= True)\n",
    "\n",
    "[data_batch,label_batch] = DataBatch(data,label,dataSize= 32*32*3,labelSize= 1,\n",
    "                                                   isShuffle= True,batchSize= 64)\n",
    "# save\n",
    "GenLog = []\n",
    "losses = []\n",
    "saver = tf.train.Saver(var_list=[var for var in tf.trainable_variables()\n",
    "                                 if var.name.startswith(\"generator\")],max_to_keep=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-5-0b196c9b7833>:9: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "step 1... Discriminator Loss: -0.0178... Generator Loss: 0.0311...\n",
      "step 6... Discriminator Loss: -0.0319... Generator Loss: 0.0435...\n",
      "INFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.CancelledError'>, Session has been closed.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-0b196c9b7833>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mbatch_noise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoise_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# noise(normal)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         _ = sess.run(g_train_opt, feed_dict={inputs_real: batch_images,\n\u001b[0;32m---> 30\u001b[0;31m                                              inputs_noise: batch_noise})\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msteps\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m5\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/8810/lib/python3.6/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 956\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    957\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/8810/lib/python3.6/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1180\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1181\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/8810/lib/python3.6/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1357\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1359\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1360\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/8810/lib/python3.6/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1363\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1365\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1366\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/8810/lib/python3.6/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0;32m-> 1350\u001b[0;31m                                       target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/8810/lib/python3.6/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1441\u001b[0m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001b[1;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1443\u001b[0;31m                                             run_metadata)\n\u001b[0m\u001b[1;32m   1444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1445\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "\n",
    "    Dir()\n",
    "\n",
    "    init = (tf.global_variables_initializer(), tf.local_variables_initializer())\n",
    "    sess.run(init)\n",
    "\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "    \n",
    "    time_start = time.time() # start timing\n",
    "    for steps in range(max_iters):\n",
    "        steps += 1\n",
    "\n",
    "        if steps < 25 or steps % 500 == 0:\n",
    "            critic_num = 100\n",
    "        else:\n",
    "            critic_num = CRITIC_NUM\n",
    "\n",
    "        for i in range(CRITIC_NUM):\n",
    "            batch_images = batch_preprocess(data_batch)  # images\n",
    "            batch_noise = np.random.normal(size=(batch_size, noise_size))  # noise(normal)\n",
    "            _ = sess.run(d_train_opt, feed_dict={inputs_real: batch_images,\n",
    "                                                 inputs_noise: batch_noise})\n",
    "            sess.run(d_clip_opt)\n",
    "\n",
    "        batch_images = batch_preprocess(data_batch)  # images\n",
    "        batch_noise = np.random.normal(size=(batch_size, noise_size))  # noise(normal)\n",
    "        _ = sess.run(g_train_opt, feed_dict={inputs_real: batch_images,\n",
    "                                             inputs_noise: batch_noise})\n",
    "\n",
    "        if steps % 5 == 1:\n",
    "\n",
    "            train_loss_d = d_loss.eval({inputs_real: batch_images,\n",
    "                                        inputs_noise: batch_noise})\n",
    "            train_loss_g = g_loss.eval({inputs_real: batch_images,\n",
    "                                        inputs_noise: batch_noise})\n",
    "            losses.append([train_loss_d, train_loss_g,steps])\n",
    "\n",
    "\n",
    "            batch_noise = np.random.normal(size=(batch_size, noise_size))\n",
    "            gen_samples = sess.run(g_test, feed_dict={inputs_noise: batch_noise})\n",
    "            genLog = (gen_samples[0:11] + 1) / 2\n",
    "            GenLog.append(genLog)\n",
    "\n",
    "\n",
    "            print('step {}...'.format(steps),\n",
    "                  \"Discriminator Loss: {:.4f}...\".format(train_loss_d),\n",
    "                  \"Generator Loss: {:.4f}...\".format(train_loss_g))\n",
    "\n",
    "        if steps % 500 ==0:\n",
    "            saver.save(sess, './Wgan_ckpt/generator.ckpt', global_step=steps)\n",
    "\n",
    "    coord.request_stop()\n",
    "    coord.join(threads)\n",
    "    \n",
    "#end timing\n",
    "time_end = time.time()\n",
    "print('Finished! Time：%.2f s.'%(time_end-time_start))\n",
    "\n",
    "# Save info\n",
    "with open('./Wgan_trainLog/loss_variation.loss', 'wb') as l:\n",
    "    losses = np.array(losses)\n",
    "    pickle.dump(losses,l)\n",
    "    print('Saving loss info...')\n",
    "    \n",
    "with open('./Wgan_trainLog/GenLog.log', 'wb') as g:\n",
    "    pickle.dump(GenLog, g)\n",
    "    print('Saving GenLog inof..')\n",
    "    \n",
    "with open('./Wgan_trainLog/loss_variation.loss', 'wb') as l:\n",
    "    losses = np.array(losses)\n",
    "    pickle.dump(losses,l)\n",
    "    print('loss saved')\n",
    "\n",
    "with open('./Wgan_trainLog/GenLog.log', 'wb') as g:\n",
    "    pickle.dump(GenLog, g)\n",
    "    print('GenLog saved..')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output\n",
    "with open('./Wgan_trainLog/GenLog.log', 'rb') as f:\n",
    "\n",
    "    GenLog = pickle.load(f)\n",
    "    GenLog = np.array(GenLog)\n",
    "    ImgShow(GenLog,[-1],10)\n",
    "\n",
    "with open(r'./Wgan_trainLog/loss_variation.loss','rb') as l:\n",
    "    losses = pickle.load(l)\n",
    "    fig, ax = plt.subplots(figsize=(20, 7))\n",
    "    plt.plot(losses.T[2],losses.T[0], label='Discriminator  Loss')\n",
    "    plt.plot(losses.T[2],losses.T[1], label='Generator Loss')\n",
    "    plt.title(\"Training Losses\")\n",
    "    plt.xlabel('iterations')\n",
    "    plt.ylabel('loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    meta_graph = tf.train.import_meta_graph('./Wgan_ckpt/generator.ckpt-35000.meta')\n",
    "    meta_graph.restore(sess,tf.train.latest_checkpoint('./Wgan_ckpt'))\n",
    "    graph = tf.get_default_graph()\n",
    "    inputs_noise = graph.get_tensor_by_name(\"inputs_noise:0\")\n",
    "    d_outputs_fake = graph.get_tensor_by_name(\"generator/Tanh:0\")\n",
    "    sample_noise= np.random.normal(size=(10, 128))\n",
    "    gen_samples = sess.run(d_outputs_fake,feed_dict={inputs_noise: sample_noise})\n",
    "    gen_samples = [(gen_samples[0:11]+1)/2]\n",
    "    ImgShow(gen_samples, [0], 10)\n",
    "    for i in range(10):\n",
    "        img=gen_samples[0][i]\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')\n",
    "        plt.savefig(\"wgan_img/car_%d.png\" % i)\n",
    "        plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow",
   "language": "python",
   "name": "8810"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
